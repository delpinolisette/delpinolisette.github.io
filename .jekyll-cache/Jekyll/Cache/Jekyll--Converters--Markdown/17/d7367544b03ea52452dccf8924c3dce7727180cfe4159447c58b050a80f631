I"ü<p>Itâ€™s always incredible to see how some simple algebraic manipulation can make your work easier when building models in Machine Learning. For example, the Maximum Likelihood Estimate reduces to a lovely sum in the case of two classifiers. More discussion coming soon, but Iâ€™ve been reading about this across several papers and technical blogs:</p>

<ul>
  <li>Elements of Statistical Inference (my Bible)</li>
  <li><a href="https://web.stanford.edu/class/archive/cs/cs109/cs109.1178/lectureHandouts/220-logistic-regression.pdf">Logistic Regression Handout from Stanford CS 109</a></li>
  <li><a href="https://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch12.pdf">CMU Stat Dept handout</a></li>
  <li><a href="https://czep.net/stat/mlelr.pdf">CZepâ€™s Paper</a></li>
  <li><a href="https://www.stat.rutgers.edu/home/pingli/papers/Logit.pdf">Rutgers Slides on Logit</a></li>
</ul>

<p>I hope these links ride forever on the endless highway of the internet, shiny and chrome (please donâ€™t be broken in a year)</p>
:ET