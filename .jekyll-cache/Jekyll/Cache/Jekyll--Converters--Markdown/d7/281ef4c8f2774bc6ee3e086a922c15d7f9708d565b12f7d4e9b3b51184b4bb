I"Ú<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<h2 id="what-is-the-goal-of-maximum-likelihood-estimate">What is the Goal of Maximum Likelihood Estimate?</h2>

<ul>
  <li>The goal of ML (max likelihood) is to find the optimal way to fit a <strong>distribution to your data</strong>.</li>
  <li>MLE is the answer to the question ‚Äúwhat does my underlying model look like?‚Äù</li>
  <li>
    <p>when we estimate values we think in terms of maximum likelihood estimates for parameters that we care about, such as the mean \(\mu\), or the maximum likelihood estimation for the standard deviation \(\sqrt{\sigma}\)</p>
  </li>
  <li>A useful example, for me at least is the role MLE in <strong>Logistic Regression</strong> (makes the most visual sense).</li>
</ul>

<p>Note from 03-22-2021‚Ä¶</p>

<p>A longer writeup is coming up soon, but in the case where you only have to classes in your classification (ex. hotdog or not a hotdog (haha‚Ä¶.)) the MLE simplifies to a different, simpler sum. And by simpler I mean a sum that doesn‚Äôt cause numerical underflow in Python by avoiding the case of <code class="language-plaintext highlighter-rouge">log(0) = -inf</code>.</p>

:ET