---
title: "Elements of Statistical Inference"
author: Lisette del Pino
layout: post
---

It's always incredible to see how some simple algebraic manipulation can make your work easier when building models in Machine Learning. For example, the Maximum Likelihood Estimate reduces to a lovely sum in the case of two classifiers. More discussion coming soon, but I've been reading about this across several papers and technical blogs:

- Elements of Statistical Inference (my Bible)
- [Logistic Regression Handout from Stanford CS 109](https://web.stanford.edu/class/archive/cs/cs109/cs109.1178/lectureHandouts/220-logistic-regression.pdf)
- [CMU Stat Dept handout](https://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch12.pdf)
- [CZep's Paper](https://czep.net/stat/mlelr.pdf)
- [Rutgers Slides on Logit](https://www.stat.rutgers.edu/home/pingli/papers/Logit.pdf)


<!-- I hope these links ride forever on the endless highway of the internet, shiny and chrome (please don't be broken in a year) -->